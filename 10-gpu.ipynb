{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f17f58",
   "metadata": {},
   "source": [
    "# GPU\n",
    "\n",
    "Le calcul sur GPU permet de calculer plus rapidement certaines opérations mathématiques.\n",
    "Il est particulièrement bien adapté pour les opérations simples entre tableaux de grandes\n",
    "dimensions. Il consiste à déporter les calculs sur la carte graphique puis récupérer les résultats.\n",
    "Ces transferts de données ont un coût qu'il faudra prendre en compte lors de l'utilisation\n",
    "de ces co-processeurs.\n",
    "\n",
    "On importe quelques packages pour nos exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "using Random\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "using ForwardDiff\n",
    "using ProgressMeter\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a3623b",
   "metadata": {},
   "source": [
    "Le package principal qui permet d'utiliser est `CUDA.jl`, il permet d'utiliser les cartes \n",
    "graphiques de la marque NVIDIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3800a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CUDA\n",
    "\n",
    "CUDA.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9909ef",
   "metadata": {},
   "source": [
    "Lorsque vous installez `CUDA.jl`, une version du compilateur de NVIDIA sera également téléchargé\n",
    "sur votre poste. Il est possible d'utiliser une installation existante, c'est expliqué dans la \n",
    "documentation.\n",
    "\n",
    "Cette première fonction permet de vérifier que le package est correctement installé et que vous disposez\n",
    "de la carte graphique adéquate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.functional()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacf7b7d",
   "metadata": {},
   "source": [
    "Vous pouvez également lister les matériels à votre disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895369d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for device in CUDA.devices()\n",
    "    @show capability(device)\n",
    "    @show name(device)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e200c1",
   "metadata": {},
   "source": [
    "Pour tester votre installation vous pouvez également regarder le package [GPUInspector.jl](https://pc2.github.io/GPUInspector.jl/dev/)\n",
    "\n",
    "## Création de tableaux pour le GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c184cb",
   "metadata": {},
   "source": [
    "### Allocations sur la carte graphique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CuArray{Float32,2}(undef, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b664912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56aaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CuArray([1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0ec99",
   "metadata": {},
   "source": [
    "## Transfert vers le CPU\n",
    "\n",
    "`b` est alloué sur le CPU, et un transfert de données est effectué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6764d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99753f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119a24ff",
   "metadata": {},
   "source": [
    "### Compatibilité avec les tableaux Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca12bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c41c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CUDA.zeros(Float32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f7f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a isa AbstractArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84c1a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.fill(42, (3,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438753e",
   "metadata": {},
   "source": [
    "## Tirages aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbeb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.rand(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df509f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.randn(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1605816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = CUDA.CuArray(0:0.01:1.0)\n",
    "nt = length(x)\n",
    "y = 0.2 .+ 0.5 .* x + 0.1 .* CUDA.randn(nt);\n",
    "scatter( Array(x), Array(y))\n",
    "plot!( x -> 0.2 + 0.5x)\n",
    "xlims!(0,1)\n",
    "ylims!(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9211a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hcat(CUDA.ones(nt), x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987cb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "β = X'X \\ X'y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa29b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum( ( β[1] .+ β[2] .* x .- y).^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca469664",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CuArray([1 2 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "view(a, 2:3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee662b6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "a = CuArray{Float64}([1 2 3])\n",
    "b = CuArray{Float64}([4 5 6])\n",
    "\n",
    "map(a) do x\n",
    "    x + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184a4b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "reduce(+, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5bdfb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "accumulate(+, b; dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf4b60",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "findfirst(isequal(2), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d578784",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "a = CuArray([1 2 3])\n",
    "b = CuArray([4 5 6])\n",
    "\n",
    "map(a) do x\n",
    "    x + 1\n",
    "end\n",
    "\n",
    "a .+ 2b\n",
    "\n",
    "reduce(+, a)\n",
    "\n",
    "accumulate(+, b; dims=2)\n",
    "\n",
    "findfirst(isequal(2), a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cbd01",
   "metadata": {},
   "source": [
    "# CURAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961b4e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.rand!(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a721c09",
   "metadata": {},
   "source": [
    "# CUBLAS\n",
    "\n",
    "Les opérations entre tableaux alloués sur le GPU sont effectués sur le co-processeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fd216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80f704",
   "metadata": {},
   "source": [
    "# CUSOLVER\n",
    "\n",
    "Certaines fonctions d'algèbre linéaire de LAPACK sont disponibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ce435",
   "metadata": {},
   "outputs": [],
   "source": [
    "L, ipiv = CUDA.CUSOLVER.getrf!(a'b)\n",
    "CUDA.CUSOLVER.getrs!('N', L, ipiv, CUDA.ones(Float64, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d967f18",
   "metadata": {},
   "source": [
    "# CUFFT\n",
    "\n",
    "Pour faire des FFTs sur le GPU, il est nécessaire d'utiliser les `plans` pour allouer l'espace nécessaire sur la carte graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft = CUFFT.plan_fft(a) \n",
    "fft * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e725ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifft = CUFFT.plan_ifft(a)\n",
    "real(ifft * (fft * a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b490e43",
   "metadata": {},
   "source": [
    "# CUDDN\n",
    "\n",
    "Vous avez également accès à la bibliothèque NVIDIA pour les réseaux de neurones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30f403",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.CUDNN.softmax(real(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3edf831",
   "metadata": {},
   "source": [
    "# CUSPARSE\n",
    "\n",
    "Les formats destinés aux matrices creuses sont aussi disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.CUSPARSE.CuSparseMatrixCSR(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9a330a",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "Les étapes pour porter votre code sur GPU\n",
    "\n",
    "1. Développez votre application sur votre CPU avec les tabeaux de type `Array`\n",
    "2. port your application to the GPU by switching to the CuArray type\n",
    "3. disallow the CPU fallback (\"scalar indexing\") to find operations that are not implemented for or incompatible with GPU execution\n",
    "4. (optional) use lower-level, CUDA-specific interfaces to implement missing functionality or optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb3b51",
   "metadata": {},
   "source": [
    "## Exemple avec une regression linéaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# squared error loss function\n",
    "loss(w, b, x, y) = sum(abs2, y - (w*x .+ b)) / size(y, 2)\n",
    "# get gradient w.r.t to `w`\n",
    "loss∇w(w, b, x, y) = ForwardDiff.gradient(w -> loss(w, b, x, y), w)\n",
    "# get derivative w.r.t to `b` (`ForwardDiff.derivative` is\n",
    "# used instead of `ForwardDiff.gradient` because `b` is\n",
    "# a scalar instead of an array)\n",
    "lossdb(w, b, x, y) = ForwardDiff.derivative(b -> loss(w, b, x, y), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proximal gradient descent function\n",
    "function train(w, b, x, y; lr=0.1)\n",
    "    w -= lmul!(lr, loss∇w(w, b, x, y))\n",
    "    b -= lr * lossdb(w, b, x, y)\n",
    "    return w, b\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ea6f6",
   "metadata": {},
   "source": [
    "Version CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60945c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "function cpu_test(n = 1000, p = 100, iter = 100)\n",
    "    x = randn(n, p)'\n",
    "    y = sum(x[1:5,:]; dims=1) .+ randn(n)' * 0.1\n",
    "    w = 0.0001 * randn(1, p)\n",
    "    b = 0.0\n",
    "    for i = 1:iter\n",
    "       w, b = train(w, b, x, y)\n",
    "    end\n",
    "    return loss(w,b,x,y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba4650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time cpu_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932fb58f",
   "metadata": {},
   "source": [
    "### Version GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5f6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gpu_test( n = 1000, p = 100, iter = 100)\n",
    "    x = randn(n, p)'\n",
    "    y = sum(x[1:5,:]; dims=1) .+ randn(n)' * 0.1\n",
    "    w = 0.0001 * randn(1, p)\n",
    "    b = 0.0\n",
    "    x = CuArray(x)\n",
    "    y = CuArray(y)\n",
    "    w = CuArray(w)\n",
    "    \n",
    "    for i = 1:iter\n",
    "       w, b = train(w, b, x, y)\n",
    "       \n",
    "    end\n",
    "    return loss(w,b,x,y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355b1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time gpu_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76173cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime cpu_test( 10000, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a636f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime gpu_test( 10000, 100, 100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d539f48",
   "metadata": {},
   "source": [
    "# Noyaux CUDA\n",
    "\n",
    "L'écriture directe de noyaux CUDA est possible, cependant:\n",
    "- les allocations sont interdites,\n",
    "- pas d'entrées-sorties donc pas d'affichage,\n",
    "- si votre code n'est pas typé correctement, le code compilé sera peu performant.\n",
    "\n",
    "Programmer vos noyaux de manière incrémentale, en les gardant le plus simple possible et en vérifiant\n",
    "soigneusement que le résultat escompté est correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31173b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CUDA.zeros(1024)\n",
    "\n",
    "function kernel(a)\n",
    "    i = threadIdx().x\n",
    "    a[i] += 1\n",
    "    return\n",
    "end\n",
    "\n",
    "@cuda threads=length(a) kernel(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07718344",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CUDA.rand(Int, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206c18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c979d58",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "@btime norm($a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb93f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime norm($(Array(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d946298",
   "metadata": {},
   "source": [
    "La fonction `norm` est bine plus rapide exécutée sur le CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43276e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.allowscalar(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7334c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CuArray(1:9_999_999);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d066758",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time a .+ reverse(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccd9767",
   "metadata": {},
   "source": [
    "Pour effectuer cette dernière instruction, vous avez besoin de programmer deux noyaux.\n",
    "La macro `@time` n'est pas adéquate pour évaluer la performance car on a affaire à une opération de type \"lazy\". C'est à dire que l'expression est programmée sur le GPU mais pas exécutée. Elle le sera lorsque vous transférerez le résultat vers le CPU. Vous pouvez utiliser `@sync` ou\n",
    "`@time` du package `CUDA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dc713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@time CUDA.@sync a .+ reverse(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809dcfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.@time a .+ reverse(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca379bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime CUDA.@sync $a .+ reverse($a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2910b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime CUDA.@sync $(Array(a)) .+ reverse($(Array(a)));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03a7cb1",
   "metadata": {},
   "source": [
    "## Aide au développement\n",
    "\n",
    "Vous avez quelques macros disponibles pour vous aidez à implémenter vos noyaux:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f473a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel() = (@cuprintln(\"foo\"); return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e767fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0957c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel() = (@cuprintln(\"bar\"); return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda kernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1f169",
   "metadata": {},
   "source": [
    "Attention, exécuter plusieurs noyaux CUDA à la suite prend du temps car il y a un temps de lattence\n",
    "plus important que sur CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CuArray(1:9_999_999)\n",
    "c = similar(a)\n",
    "c .= a .+ reverse(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function vadd_reverse(c, a, b)\n",
    "    i = threadIdx().x\n",
    "    if i <= length(c)\n",
    "        @inbounds c[i] = a[i] + reverse(b)[i]\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a08405a",
   "metadata": {},
   "source": [
    "Essayons de remplacer la fonction `reverse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c0069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function vadd_reverse(c, a, b)\n",
    "    \n",
    "    i = threadIdx().x\n",
    "    if i <= length(c)\n",
    "        @inbounds c[i] = a[i] + b[end - i + 1]\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696772a",
   "metadata": {},
   "source": [
    "Cela ne fonctionne pas car on n'itère pas sur un tableau alloué sur un GPU de la même manière qu'un tableau alloué sur CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4750f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda threads = length(a) vadd_reverse(c, a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f446669",
   "metadata": {},
   "source": [
    "Les fonctions `blockIdx` et `threadIdx` sont disponibkes pour vous aider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11807089",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute(device(), CUDA.DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1784d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function vadd_reverse(c, a, b)\n",
    "    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x\n",
    "    if i <= length(c)\n",
    "        @inbounds c[i] = a[i] + b[end - i + 1]\n",
    "    end\n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac4adfd",
   "metadata": {},
   "source": [
    "Le noyau construit est plus rapide que la fonction `reverse` initialement utilisée:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1437b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime CUDA.@sync @cuda threads=1024 blocks=length($a)÷1024+1 vadd_reverse($c, $a, $a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038e62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@btime CUDA.@sync $a .+ reverse($a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8cf6d4",
   "metadata": {},
   "source": [
    "Vous pouvez automatiser la configuration du noyau aux caractéristiques de votre carte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb08dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "function configurator(kernel)\n",
    "    config = launch_configuration(kernel.fun)\n",
    "    threads = min(length(a), config.threads)\n",
    "    blocks = cld(length(a), threads)\n",
    "    return (threads=threads, blocks=blocks)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25743aa5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "@cuda config=configurator vadd_reverse(c, a, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fb6793",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "julia",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
